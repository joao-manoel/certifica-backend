import type { Job } from "bull"
import { prisma } from "@/lib/prisma"
import { redis } from "@/lib/redis"

/**
 * Chaves usadas no track:
 * - pv:pending:<postId>  (contador a aplicar no banco)
 * - pv:u:<postId>:<yyyymmdd> (SET de fingerprints diÃ¡rios, TTL curto)
 * - pv:hits:<postId>:<yyyymmdd> (opcional: hits crus p/ debug)
 */

async function scanPendingKeys(pattern = "pv:pending:*", count = 200) {
  let cursor = "0"
  const keys: string[] = []
  console.log(`[FlushPostViews] ğŸ§­ Iniciando SCAN no Redis...`)

  do {
    const [nextCursor, batch] = (await redis.scan(
      cursor,
      "MATCH",
      pattern,
      "COUNT",
      count,
    )) as [string, string[]]
    cursor = nextCursor
    if (batch && batch.length) {
      keys.push(...batch)
      console.log(
        `[FlushPostViews] Encontradas ${batch.length} chaves (total atÃ© agora: ${keys.length})`,
      )
    }
  } while (cursor !== "0")

  console.log(
    `[FlushPostViews] SCAN concluÃ­do. Total de chaves: ${keys.length}`,
  )
  return keys
}

async function applyChunk(
  chunk: Array<{ key: string; postId: string; val: number }>,
) {
  console.log(
    `[FlushPostViews] ğŸ§© Aplicando chunk de ${chunk.length} posts no banco...`,
  )

  const start = performance.now()
  await prisma.$transaction(
    chunk.map((item) =>
      prisma.post.update({
        where: { id: item.postId },
        data: { views: { increment: item.val } },
        select: { id: true },
      }),
    ),
  )

  const duration = performance.now() - start
  console.log(
    `[FlushPostViews] âœ… ${chunk.length} posts atualizados no banco (${duration.toFixed(1)}ms)`,
  )

  const pipeline = redis.pipeline()
  chunk.forEach((item) => pipeline.del(item.key))
  await pipeline.exec()

  console.log(`[FlushPostViews] ğŸ§¹ Chaves removidas do Redis.`)
}

export interface FlushPostViewsData {
  // vazio: Ã© um job â€œcronâ€
}

export default {
  key: "FlushPostViews",

  // rode a cada 10 min. Ajuste se precisar.
  options: {
    repeat: { cron: "*/1 * * * *" }, // a cada 10 minutos
    removeOnComplete: true,
    removeOnFail: 50,
    limiter: { max: 1, duration: 60000 }, // sÃ³ 1 execuÃ§Ã£o por minuto
  },

  async handle(_job: Job<FlushPostViewsData>) {
    console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    console.log(
      `[FlushPostViews] ğŸš€ Job iniciado Ã s ${new Date().toISOString()}`,
    )

    const t0 = performance.now()

    try {
      const keys = await scanPendingKeys()
      if (keys.length === 0) {
        console.log("[FlushPostViews] âšª Nenhuma pendÃªncia encontrada.")
        console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        return
      }

      console.log(
        `[FlushPostViews] ğŸ”¢ Lendo valores das ${keys.length} chaves...`,
      )
      const vals = await redis.mget(...keys)
      const toApply: Array<{ key: string; postId: string; val: number }> = []

      keys.forEach((key, i) => {
        const raw = vals[i]
        const n = raw ? Number(raw) : 0
        if (Number.isFinite(n) && n > 0) {
          const postId = key.split(":")[2] // pv:pending:<postId>
          if (postId) toApply.push({ key, postId, val: n })
        }
      })

      if (toApply.length === 0) {
        console.log(
          "[FlushPostViews] âšª Nenhuma chave com valor vÃ¡lido encontrada.",
        )
        console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        return
      }

      console.log(
        `[FlushPostViews] ğŸ§® SerÃ£o aplicadas ${toApply.length} atualizaÃ§Ãµes (views).`,
      )

      const CHUNK_SIZE = 100
      for (let i = 0; i < toApply.length; i += CHUNK_SIZE) {
        const chunk = toApply.slice(i, i + CHUNK_SIZE)
        console.log(
          `[FlushPostViews] ğŸ”„ Processando chunk ${i / CHUNK_SIZE + 1}/${Math.ceil(
            toApply.length / CHUNK_SIZE,
          )}`,
        )
        await applyChunk(chunk)
      }

      const elapsed = (performance.now() - t0).toFixed(0)
      console.log(`[FlushPostViews] ğŸ¯ Job concluÃ­do em ${elapsed}ms`)
    } catch (err) {
      console.error("[FlushPostViews] âŒ Erro durante execuÃ§Ã£o:", err)
    } finally {
      console.log("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    }
  },
}
